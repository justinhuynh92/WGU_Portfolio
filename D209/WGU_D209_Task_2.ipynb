{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "03df2814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 50 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   CaseOrder             10000 non-null  int64  \n",
      " 1   Customer_id           10000 non-null  object \n",
      " 2   Interaction           10000 non-null  object \n",
      " 3   UID                   10000 non-null  object \n",
      " 4   City                  10000 non-null  object \n",
      " 5   State                 10000 non-null  object \n",
      " 6   County                10000 non-null  object \n",
      " 7   Zip                   10000 non-null  int64  \n",
      " 8   Lat                   10000 non-null  float64\n",
      " 9   Lng                   10000 non-null  float64\n",
      " 10  Population            10000 non-null  int64  \n",
      " 11  Area                  10000 non-null  object \n",
      " 12  TimeZone              10000 non-null  object \n",
      " 13  Job                   10000 non-null  object \n",
      " 14  Children              10000 non-null  int64  \n",
      " 15  Age                   10000 non-null  int64  \n",
      " 16  Income                10000 non-null  float64\n",
      " 17  Marital               10000 non-null  object \n",
      " 18  Gender                10000 non-null  object \n",
      " 19  Churn                 10000 non-null  object \n",
      " 20  Outage_sec_perweek    10000 non-null  float64\n",
      " 21  Email                 10000 non-null  int64  \n",
      " 22  Contacts              10000 non-null  int64  \n",
      " 23  Yearly_equip_failure  10000 non-null  int64  \n",
      " 24  Techie                10000 non-null  object \n",
      " 25  Contract              10000 non-null  object \n",
      " 26  Port_modem            10000 non-null  object \n",
      " 27  Tablet                10000 non-null  object \n",
      " 28  InternetService       10000 non-null  object \n",
      " 29  Phone                 10000 non-null  object \n",
      " 30  Multiple              10000 non-null  object \n",
      " 31  OnlineSecurity        10000 non-null  object \n",
      " 32  OnlineBackup          10000 non-null  object \n",
      " 33  DeviceProtection      10000 non-null  object \n",
      " 34  TechSupport           10000 non-null  object \n",
      " 35  StreamingTV           10000 non-null  object \n",
      " 36  StreamingMovies       10000 non-null  object \n",
      " 37  PaperlessBilling      10000 non-null  object \n",
      " 38  PaymentMethod         10000 non-null  object \n",
      " 39  Tenure                10000 non-null  float64\n",
      " 40  MonthlyCharge         10000 non-null  float64\n",
      " 41  Bandwidth_GB_Year     10000 non-null  float64\n",
      " 42  Item1                 10000 non-null  int64  \n",
      " 43  Item2                 10000 non-null  int64  \n",
      " 44  Item3                 10000 non-null  int64  \n",
      " 45  Item4                 10000 non-null  int64  \n",
      " 46  Item5                 10000 non-null  int64  \n",
      " 47  Item6                 10000 non-null  int64  \n",
      " 48  Item7                 10000 non-null  int64  \n",
      " 49  Item8                 10000 non-null  int64  \n",
      "dtypes: float64(7), int64(16), object(27)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# importing the churn_raw_data.csv through the file path\n",
    "df = pd.read_csv('/Users/justinhuynh/Desktop/churn_clean.csv')\n",
    "\n",
    "# check all information about this file\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46f012c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Job', 'Children', 'Age', 'Income', 'Marital', 'Gender', 'Churn',\n",
      "       'Outage_sec_perweek', 'Email', 'Contacts', 'Yearly_equip_failure',\n",
      "       'Techie', 'Contract', 'InternetService', 'Phone', 'Multiple',\n",
      "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
      "       'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'PaymentMethod',\n",
      "       'Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# remove non-relevant columns \n",
    "non_relevant_columns = ['CaseOrder', 'Customer_id', 'Interaction', 'UID', 'City', 'State',\n",
    "                        'County', 'Zip', 'Lat', 'Lng', 'Population', 'Area', 'TimeZone', \n",
    "                        'Port_modem', 'Tablet', 'Item1', 'Item2', 'Item3', 'Item4', 'Item5', \n",
    "                        'Item6', 'Item7', 'Item8']\n",
    "\n",
    "df = df.drop(columns=non_relevant_columns)\n",
    "\n",
    "# verify the remaining columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6618ead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# check for missing values in the relevant columns\n",
    "relevant_columns = df.columns\n",
    "missing_values = df[relevant_columns].isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# convert 'Churn' to numeric values\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38c4757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Children', 'Age', 'Income', 'Churn', 'Outage_sec_perweek', 'Email',\n",
      "       'Contacts', 'Yearly_equip_failure', 'Tenure', 'MonthlyCharge',\n",
      "       ...\n",
      "       'OnlineSecurity_Yes', 'PaperlessBilling_Yes',\n",
      "       'PaymentMethod_Credit Card (automatic)',\n",
      "       'PaymentMethod_Electronic Check', 'PaymentMethod_Mailed Check',\n",
      "       'Phone_Yes', 'StreamingMovies_Yes', 'StreamingTV_Yes',\n",
      "       'TechSupport_Yes', 'Techie_Yes'],\n",
      "      dtype='object', length=672)\n"
     ]
    }
   ],
   "source": [
    "# list of categorical variables\n",
    "categorical_columns = ['Contract', 'DeviceProtection', 'Gender', 'InternetService', 'Job', \n",
    "                       'Marital', 'Multiple', 'OnlineBackup', 'OnlineSecurity', 'PaperlessBilling', \n",
    "                       'PaymentMethod', 'Phone', 'StreamingMovies', 'StreamingTV', 'TechSupport', 'Techie']\n",
    "\n",
    "# initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# fit and transform the categorical columns\n",
    "encoded_categorical_data = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# create a DataFrame with the encoded categorical data\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# drop the original categorical columns from the data set\n",
    "df = df.drop(columns=categorical_columns)\n",
    "\n",
    "# add the encoded categorical columns to the data set\n",
    "df = pd.concat([df, encoded_categorical_df], axis=1)\n",
    "\n",
    "# verify the columns in the feature set\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2a287a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Children       Age    Income  Churn  Outage_sec_perweek  Email  Contacts  \\\n",
      "0 -0.972338  0.720925 -0.398778      0           -0.679978     10 -1.005852   \n",
      "1 -0.506592 -1.259957 -0.641954      1            0.570331     12 -1.005852   \n",
      "2  0.890646 -0.148730 -1.070885      0            0.252347      9 -1.005852   \n",
      "3 -0.506592 -0.245359 -0.740525      0            1.650506     15  1.017588   \n",
      "4 -0.972338  1.445638  0.009478      1           -0.623156     16  1.017588   \n",
      "\n",
      "   Yearly_equip_failure    Tenure  MonthlyCharge  ...  OnlineSecurity_Yes  \\\n",
      "0              0.946658 -1.048746      -0.003943  ...                 1.0   \n",
      "1              0.946658 -1.262001       1.630326  ...                 1.0   \n",
      "2              0.946658 -0.709940      -0.295225  ...                 0.0   \n",
      "3             -0.625864 -0.659524      -1.226521  ...                 1.0   \n",
      "4              0.946658 -1.242551      -0.528086  ...                 0.0   \n",
      "\n",
      "   PaperlessBilling_Yes  PaymentMethod_Credit Card (automatic)  \\\n",
      "0                   1.0                                    1.0   \n",
      "1                   1.0                                    0.0   \n",
      "2                   1.0                                    1.0   \n",
      "3                   1.0                                    0.0   \n",
      "4                   0.0                                    0.0   \n",
      "\n",
      "   PaymentMethod_Electronic Check  PaymentMethod_Mailed Check  Phone_Yes  \\\n",
      "0                             0.0                         0.0        1.0   \n",
      "1                             0.0                         0.0        1.0   \n",
      "2                             0.0                         0.0        1.0   \n",
      "3                             0.0                         1.0        1.0   \n",
      "4                             0.0                         1.0        0.0   \n",
      "\n",
      "   StreamingMovies_Yes  StreamingTV_Yes  TechSupport_Yes  Techie_Yes  \n",
      "0                  1.0              0.0              0.0         0.0  \n",
      "1                  1.0              1.0              0.0         1.0  \n",
      "2                  1.0              0.0              0.0         1.0  \n",
      "3                  0.0              1.0              0.0         1.0  \n",
      "4                  0.0              1.0              1.0         0.0  \n",
      "\n",
      "[5 rows x 672 columns]\n"
     ]
    }
   ],
   "source": [
    "# list of numeric columns\n",
    "numeric_columns = ['Age', 'Bandwidth_GB_Year', 'Children', 'Contacts', 'Income', \n",
    "                   'MonthlyCharge', 'Outage_sec_perweek', 'Tenure', 'Yearly_equip_failure']\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the numeric columns\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# verify the scaled feature set\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae009029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prepared data to csv\n",
    "df.to_csv('cleaned_churn_data_d209_task2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0db28818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 671) (2000, 671) (8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# define the feature set (X) and the target variable (y)\n",
    "X = df.drop(columns=['Churn'])\n",
    "y = df['Churn']\n",
    "\n",
    "# split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# save the processed training and testing data to CSV files\n",
    "X_train.to_csv('X_train_task_2.csv', index=False)\n",
    "X_test.to_csv('X_test_task_2.csv', index=False)\n",
    "y_train.to_csv('y_train_task_2.csv', index=False)\n",
    "y_test.to_csv('y_test_task_2.csv', index=False)\n",
    "\n",
    "# display training and testing sets shapes\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4751a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children               float64\n",
      "Age                    float64\n",
      "Income                 float64\n",
      "Outage_sec_perweek     float64\n",
      "Email                    int64\n",
      "                        ...   \n",
      "Phone_Yes              float64\n",
      "StreamingMovies_Yes    float64\n",
      "StreamingTV_Yes        float64\n",
      "TechSupport_Yes        float64\n",
      "Techie_Yes             float64\n",
      "Length: 671, dtype: object\n",
      "Children               float64\n",
      "Age                    float64\n",
      "Income                 float64\n",
      "Outage_sec_perweek     float64\n",
      "Email                    int64\n",
      "                        ...   \n",
      "Phone_Yes              float64\n",
      "StreamingMovies_Yes    float64\n",
      "StreamingTV_Yes        float64\n",
      "TechSupport_Yes        float64\n",
      "Techie_Yes             float64\n",
      "Length: 671, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load the processed training and testing data\n",
    "X_train = pd.read_csv('X_train_task_2.csv')\n",
    "X_test = pd.read_csv('X_test_task_2.csv')\n",
    "y_train = pd.read_csv('y_train_task_2.csv')\n",
    "y_test = pd.read_csv('y_test_task_2.csv')\n",
    "\n",
    "# ensure all columns are numeric\n",
    "for column in X_train.columns:\n",
    "    if X_train[column].dtype == object:\n",
    "        print(f\"Column {column} has string values:\")\n",
    "        print(X_train[column].unique())\n",
    "        # Convert column to numeric, if possible\n",
    "        X_train[column] = X_train[column].apply(lambda x: 1 if x.strip().lower() == 'yes' else (0 if x.strip().lower() == 'no' else x))\n",
    "\n",
    "for column in X_test.columns:\n",
    "    if X_test[column].dtype == object:\n",
    "        print(f\"Column {column} has string values:\")\n",
    "        print(X_test[column].unique())\n",
    "        # Convert column to numeric, if possible\n",
    "        X_test[column] = X_test[column].apply(lambda x: 1 if x.strip().lower() == 'yes' else (0 if x.strip().lower() == 'no' else x))\n",
    "\n",
    "# verify the conversion\n",
    "print(X_train.dtypes)\n",
    "print(X_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c3b07fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1456\n",
      "           1       0.77      0.75      0.76       544\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.84      0.83      0.83      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n",
      "[[1333  123]\n",
      " [ 138  406]]\n"
     ]
    }
   ],
   "source": [
    "# ensure target variable 'y' is in correct format\n",
    "y_train = y_train.values.ravel()  # convert DataFrame to 1D array\n",
    "y_test = y_test.values.ravel()    # convert DataFrame to 1D array\n",
    "\n",
    "# initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed3d6b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1305\n"
     ]
    }
   ],
   "source": [
    "# calculate predicted probabilities\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# calculate MSE\n",
    "mse = mean_squared_error(y_test, y_prob)\n",
    "print(f\"MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191746eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
